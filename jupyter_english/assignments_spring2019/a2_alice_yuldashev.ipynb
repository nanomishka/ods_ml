{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for writing predictions to a file\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "times = ['time%s' % i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/train_sessions.csv',\n",
    "                       index_col='session_id', parse_dates=times)\n",
    "test_df = pd.read_csv('../../data/test_sessions.csv',\n",
    "                      index_col='session_id', parse_dates=times)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[sites].fillna(0).astype('int').to_csv('train_sessions_text.txt', sep=' ', index=None, header=None)\n",
    "test_df[sites].fillna(0).astype('int').to_csv('test_sessions_text.txt', sep=' ', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 50000) (82797, 50000)\n",
      "CPU times: user 10.8 s, sys: 298 ms, total: 11.1 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = TfidfVectorizer(ngram_range=(1, 3), max_features=50000, max_df=0.90, min_df=2)\n",
    "with open('train_sessions_text.txt') as inp_train_file:\n",
    "    X_train = cv.fit_transform(inp_train_file)\n",
    "with open('test_sessions_text.txt') as inp_test_file:\n",
    "    X_test = cv.transform(inp_test_file)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train targets into a separate vector\n",
    "y_train = train_df['target'].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing time series cross-validation\n",
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform time series cross-validation with logistic regression\n",
    "logit = LogisticRegression(C=1, random_state=17, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 823 ms, sys: 96.9 ms, total: 920 ms\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.81348435, 0.65520438, 0.87592305, 0.93549238, 0.84778787,\n",
       "        0.88863608, 0.9248393 , 0.8747525 , 0.92845316, 0.92313193]),\n",
       " 0.8667705000608688,\n",
       " 0.07978822332630801)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean(), cv_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'subm1.csv') # 0.91288 -> 0.91382"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# hour\n",
    "def feature_hour(df):\n",
    "    return df.fillna(0)['time1'].apply(lambda ts: ts.hour)\n",
    "\n",
    "features['hour'] = {\n",
    "    'train': feature_hour(train_df),\n",
    "    'test': feature_hour(test_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# morning\n",
    "def feature_morning(series):\n",
    "    return ((series >= 7) & (series <= 11)).astype('int')\n",
    "\n",
    "features['morning'] = {\n",
    "    'train': feature_morning(features['hour']['train']),\n",
    "    'test': feature_morning(features['hour']['test']),\n",
    "}\n",
    "\n",
    "# day\n",
    "def feature_day(series):\n",
    "    return ((series >= 12) & (series <= 18)).astype('int')\n",
    "\n",
    "features['day'] = {\n",
    "    'train': feature_day(features['hour']['train']),\n",
    "    'test': feature_day(features['hour']['test']),\n",
    "}\n",
    "\n",
    "# evening\n",
    "def feature_evening(series):\n",
    "    return ((series >= 19) & (series <= 23)).astype('int')\n",
    "\n",
    "features['evening'] = {\n",
    "    'train': feature_evening(features['hour']['train']),\n",
    "    'test': feature_evening(features['hour']['test']),\n",
    "}\n",
    "\n",
    "# night\n",
    "def feature_night(series):\n",
    "    return ((series >= 0) & (series <= 6)).astype('int')\n",
    "\n",
    "features['night'] = {\n",
    "    'train': feature_night(features['hour']['train']),\n",
    "    'test': feature_night(features['hour']['test']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration\n",
    "def feature_duration(df):\n",
    "    df_times = df[times]\n",
    "    return (df_times.max(axis=1) - df_times[times].min(axis=1)) / np.timedelta64(1, 's') / 1800\n",
    "\n",
    "features['duration'] = {\n",
    "    'train': feature_duration(train_df),\n",
    "    'test': feature_duration(test_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites\n",
    "def feature_sites(df):\n",
    "    return df[sites].count(axis=1)\n",
    "\n",
    "features['sites'] = {\n",
    "    'train': feature_sites(train_df),\n",
    "    'test': feature_sites(test_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_time\n",
    "def feature_avg_time(duration, sites):\n",
    "    return duration / sites\n",
    "\n",
    "features['avg_time'] = {\n",
    "    'train': feature_avg_time(features['duration']['train'], features['sites']['train']),\n",
    "    'test': feature_avg_time(features['duration']['test'], features['sites']['test']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_time\n",
    "def feature_first_time(df):\n",
    "    return (df['time2'] - df['time1']).fillna(0) / np.timedelta64(1, 's')\n",
    "\n",
    "features['first_time'] = {\n",
    "    'train': feature_first_time(train_df),\n",
    "    'test': feature_first_time(test_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "def feature_2014(df):\n",
    "    return (df['time1'].apply(lambda ts: ts.year) == 2014).astype('int')\n",
    "\n",
    "features['2014'] = {\n",
    "    'train': feature_2014(train_df),\n",
    "    'test': feature_2014(test_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_set(cols, is_test=False):\n",
    "    return hstack([\n",
    "        X_test if is_test else X_train, \n",
    "        *[features[col]['test' if is_test else 'train'].values.reshape(-1, 1) for col in cols]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (\n",
    "#         'hour', # 3.41\n",
    "        'morning',  # 4.58\n",
    "        'day',  # 4.61\n",
    "        'evening',  # 0.15\n",
    "        'night',  # -\n",
    "#         'duration',  # 0.06\n",
    "#         'sites',  # -\n",
    "#         'avg_time',  # -\n",
    "#         'first_time',  # 0\n",
    "#         '2014',  # 0.1\n",
    "    )\n",
    "\n",
    "X_train_new = prepare_set(columns)\n",
    "X_test_new = prepare_set(columns, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 977 ms, sys: 105 ms, total: 1.08 s\n",
      "Wall time: 4.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# performing time series cross-validation, we see an improvement in ROC AUC\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "cv_scores = cross_val_score(logit, X_train_new, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.87008266, 0.80648914, 0.92857517, 0.96592745, 0.91598991,\n",
       "        0.9516962 , 0.94826252, 0.93866035, 0.95200296, 0.95071618]),\n",
       " 0.9228402542341649,\n",
       " 0.05391040420543547)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean(), cv_scores.mean() - 0.8689298500287295\n",
    "# (array([0.87008266, 0.80648914, 0.92857517, 0.96592745, 0.91598991,\n",
    "        0.9516962 , 0.94826252, 0.93866035, 0.95200296, 0.95071618]),\n",
    "#0.9228402542341649,\n",
    " 0.05391040420543547)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(X_train_new, y_train)\n",
    "\n",
    "logit_test_pred2 = logit.predict_proba(X_test_new)[:, 1]\n",
    "write_to_submission_file(logit_test_pred2, 'subm2.csv') # 0.93843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune regularization parameter C\n",
    "c_values = np.logspace(-2, 2, 10)\n",
    "\n",
    "logit_grid_searcher = GridSearchCV(\n",
    "    estimator=logit, param_grid={'C': c_values}, scoring='roc_auc', n_jobs=1, cv=time_split, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 41s, sys: 1min 8s, total: 7min 50s\n",
      "Wall time: 2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e-02, 2.78256e-02, 7.74264e-02, 2.15443e-01, 5.99484e-01,\n",
       "       1.66810e+00, 4.64159e+00, 1.29155e+01, 3.59381e+01, 1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher.fit(X_train_new, y_train) # WTF? Locally, it's 3min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9249450807614793, {'C': 1.6681005372000592})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher.best_score_, logit_grid_searcher.best_params_  # (0.9249450807614793, {'C': 1.6681005372000592})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred3 = logit_grid_searcher.predict_proba(X_test_new)[:, 1]\n",
    "write_to_submission_file(logit_test_pred3, 'subm3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 97.3 ms, total: 1.19 s\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# performing time series cross-validation, we see an improvement in ROC AUC\n",
    "cv_scores = cross_val_score(logit_grid_searcher.best_estimator_, X_train_new, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.88342964, 0.80461656, 0.93157956, 0.9669782 , 0.91693854,\n",
       "        0.95127441, 0.95164868, 0.93786943, 0.95342815, 0.95168763]),\n",
       " 0.9249450807614791,\n",
       " 0.04601868425363776)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean(), cv_scores.std() # 0.9249450807614791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred3 = logit_grid_searcher.predict_proba(X_test_new)[:, 1]\n",
    "write_to_submission_file(logit_test_pred3, 'subm5.csv') # 0.94637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
